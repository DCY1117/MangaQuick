{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFolders = [\n",
    "     'ARMS',\n",
    "     'AisazuNihaIrarenai',\n",
    "     'AkkeraKanjinchou',\n",
    "     'Akuhamu',\n",
    "     'AosugiruHaru',\n",
    "     'AppareKappore',\n",
    "     'Arisa',\n",
    "     'BEMADER_P',\n",
    "     'BakuretsuKungFuGirl',\n",
    "     'Belmondo',\n",
    "     'BokuHaSitatakaKun',\n",
    "     'BurariTessenTorimonocho',\n",
    "     'ByebyeC-BOY',\n",
    "     'Count3DeKimeteAgeru',\n",
    "     'DollGun',\n",
    "     'Donburakokko',\n",
    "     'DualJustice',\n",
    "     'EienNoWith',\n",
    "     'EvaLady',\n",
    "     'EverydayOsakanaChan',\n",
    "     'GOOD_KISS_Ver2',\n",
    "     'GakuenNoise',\n",
    "     'GarakutayaManta',\n",
    "     'GinNoChimera',\n",
    "     'Hamlet',\n",
    "     'HanzaiKousyouninMinegishiEitarou',\n",
    "     'HaruichibanNoFukukoro',\n",
    "     'HarukaRefrain',\n",
    "     'HealingPlanet',\n",
    "     \"UchiNoNyan'sDiary\",\n",
    "     'UchuKigekiM774',\n",
    "     'UltraEleven',\n",
    "     'UnbalanceTokyo',\n",
    "     'WarewareHaOniDearu',\n",
    "     'YamatoNoHane',\n",
    "     'YasasiiAkuma',\n",
    "     'YouchienBoueigumi',\n",
    "     'YoumaKourin',\n",
    "     'YukiNoFuruMachi',\n",
    "     'YumeNoKayoiji',\n",
    "     'YumeiroCooking',\n",
    "     'TotteokiNoABC',\n",
    "     'ToutaMairimasu',\n",
    "     'TouyouKidan',\n",
    "     'TsubasaNoKioku'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np   \n",
    "import utils as U   \n",
    "import glob\n",
    "from PIL import Image\n",
    "from pathlib import Path   \n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import models as M\n",
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n",
    "from keras import callbacks\n",
    "import keras\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, fold, patches = 40, train = False, dims=(128,128), shuffle=True):\n",
    "        self.shuffle = shuffle\n",
    "        self.patches = patches\n",
    "        self.train = train\n",
    "        self.dims = dims\n",
    "        self.fold = list(KFold(n_splits = 5, shuffle = True, random_state=42).split(trainFolders, trainFolders))[fold]\n",
    "        self.init_images()\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def init_images(self):\n",
    "        self.images = []\n",
    "        for f in glob.glob(\"/data/anime/masks/**/*.cache\"):\n",
    "            index = trainFolders.index(Path(f).parent.name)\n",
    "            if index in self.fold[0] and self.train:\n",
    "                self.images.append(f)\n",
    "            elif index in self.fold[1] and not self.train:\n",
    "                self.images.append(f)\n",
    "        #self.images = self.images[0:3]\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.images)))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation([self.images[index]])\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.images))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, files):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        images = []\n",
    "        masks = []\n",
    "        \n",
    "        for f in files:\n",
    "            mask = np.array(Image.open(f))\n",
    "            mask[mask >= 3] -= 3\n",
    "            mask = (mask != 0) * 255\n",
    "            img = np.asarray(Image.open('/data/anime/manga/Manga109_2017_09_28/images/' + Path(f).parent.name + '/' + Path(f).stem + '.jpg').convert('L'))\n",
    "            images.append(img)\n",
    "            masks.append(mask)\n",
    "        \n",
    "        patches_image, patches_masks = U.extract_random(images, masks, *self.dims, self.patches)\n",
    "        \n",
    "        patches_image /= 255.\n",
    "        patches_masks /= 255.       \n",
    "        \n",
    "        patches_image  = np.expand_dims(patches_image,  axis = 3)\n",
    "        patches_masks = np.expand_dims(patches_masks, axis = 3)\n",
    "        return patches_image, patches_masks\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(index):\n",
    "    train = DataGenerator(index, train=True)\n",
    "    test = DataGenerator(index, train=False)\n",
    "    print('Dataset Prepared')\n",
    "\n",
    "    model = M.BCDU_net_D3(input_size = (128, 128, 1))\n",
    "    model.summary()\n",
    "\n",
    "    print('Training')\n",
    "\n",
    "    nb_epoch = 20\n",
    "\n",
    "    mcp_save = ModelCheckpoint('weight_text'+str(index)+'.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='min')\n",
    "\n",
    "    history = model.fit(x=train,\n",
    "                  epochs=nb_epoch,\n",
    "                  verbose=1,\n",
    "                  validation_data=test, callbacks=[mcp_save, reduce_lr_loss] )\n",
    "\n",
    "    print('Trained model saved')\n",
    "    with open('fold' + str(index), 'wb') as file_pi:\n",
    "            pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Prepared\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0904 03:00:48.262387 139725218301696 callbacks.py:2323] `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 128, 128, 64) 640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 64) 36928       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 64, 64, 64)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 128)  73856       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 128)  147584      conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 128)  0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 256)  295168      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 256)  590080      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 256)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 512)  1180160     max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 512)  2359808     conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16, 16, 512)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 512)  2359808     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 512)  2359808     conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 16, 16, 512)  0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 16, 16, 1024) 0           dropout_2[0][0]                  \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 512)  4719104     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 512)  2359808     conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16, 16, 512)  0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 32, 32, 256)  524544      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 256)  1024        conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32, 32, 256)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 256)  0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1, 32, 32, 25 0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 32, 32, 25 0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2, 32, 32, 25 0           reshape[0][0]                    \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d (ConvLSTM2D)       (None, 32, 32, 128)  1769984     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 256)  295168      conv_lst_m2d[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 256)  590080      conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 64, 64, 128)  131200      conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 128)  512         conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 128)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 64, 64, 12 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 64, 64, 12 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 2, 64, 64, 12 0           reshape_2[0][0]                  \n",
      "                                                                 reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_1 (ConvLSTM2D)     (None, 64, 64, 64)   442624      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 128)  73856       conv_lst_m2d_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 128)  147584      conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 128, 128, 64) 32832       conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 128, 64) 256         conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 128, 128, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 1, 128, 128,  0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 1, 128, 128,  0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 2, 128, 128,  0           reshape_4[0][0]                  \n",
      "                                                                 reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_2 (ConvLSTM2D)     (None, 128, 128, 32) 110720      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 128, 128, 64) 18496       conv_lst_m2d_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 64) 36928       conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 2)  1154        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 128, 1)  3           conv2d_18[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 20,659,717\n",
      "Trainable params: 20,658,821\n",
      "Non-trainable params: 896\n",
      "__________________________________________________________________________________________________\n",
      "Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "360/360 [==============================] - 292s 811ms/step - loss: 0.1528 - accuracy: 0.9642 - val_loss: 0.1258 - val_accuracy: 0.9681\n",
      "Epoch 2/20\n",
      "360/360 [==============================] - 289s 803ms/step - loss: 0.1127 - accuracy: 0.9664 - val_loss: 0.1294 - val_accuracy: 0.9683\n",
      "Epoch 3/20\n",
      "360/360 [==============================] - 290s 807ms/step - loss: 0.1005 - accuracy: 0.9699 - val_loss: 0.1030 - val_accuracy: 0.9703\n",
      "Epoch 4/20\n",
      "360/360 [==============================] - 289s 802ms/step - loss: 0.0884 - accuracy: 0.9733 - val_loss: 0.1331 - val_accuracy: 0.9682\n",
      "Epoch 5/20\n",
      "278/360 [======================>.......] - ETA: 1:00 - loss: 0.0852 - accuracy: 0.9747"
     ]
    }
   ],
   "source": [
    "train(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in range(0, 5):\n",
    "    model = M.BCDU_net_D3(input_size = (128, 128,1))\n",
    "    model.load_weights('weight_text'+str(fold)+'.hdf5')\n",
    "    test = DataGenerator(fold, train=False)\n",
    "\n",
    "    for f in test.images:\n",
    "        img = np.asarray(Image.open('/data/anime/manga/Manga109_2017_09_28/images/' + Path(f).parent.name + '/' + Path(f).stem + '.jpg').convert('L'))\n",
    "        patches , new_h, new_w = U.extract_ordered_overlap(img, 128, 128, 64, 64)\n",
    "        patches     = np.expand_dims(patches,  axis = 3)\n",
    "        predictions = model.predict(patches, batch_size= 40, verbose=1)\n",
    "        estimated   = U.recompone_overlap(predictions[:,:,:,0], new_h, new_w, 64, 64)\n",
    "        estimated   = np.where(estimated >= 0.7, 1, 0)\n",
    "        save_path = '/data/anime/predictions/' + Path(f).parent.name\n",
    "        Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "        Image.fromarray(estimated.astype(np.uint8)).save(save_path  + '/' + Path(f).stem + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(90.)\n",
      "1 tensor(0.)\n",
      "2 tensor(0.)\n",
      "3 tensor(90.)\n",
      "4 tensor(90.)\n"
     ]
    }
   ],
   "source": [
    "for fold in range(0, 5):\n",
    "    test = DataGenerator(fold, train=False)\n",
    "    count = 0\n",
    "    for f in test.images:\n",
    "        pred = open_mask('/data/anime/predictions/' + Path(f).parent.name + '/' + Path(f).stem + '.png').px\n",
    "        count += pred.max()\n",
    "    print(fold, count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
