{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import fastai\n",
    "from experiments import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from losses import MixedLoss\n",
    "from dataset import *\n",
    "from transforms import *\n",
    "from config import *\n",
    "import glob\n",
    "from PIL import Image as pilImage\n",
    "from metrics import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_PATH = Path(EXPERIMENTS_PATH) / 'synthetic'\n",
    "\n",
    "def custom_loss(pred, truth):\n",
    "    truth = truth.float()\n",
    "    return F.binary_cross_entropy(pred, truth)\n",
    "\n",
    "def custom_collate(batch):\n",
    "    if isinstance(batch[0][1], int):\n",
    "        return torch.stack(list(map(lambda x: x[0].data, batch))), torch.stack(list(map(lambda x: tensor(x[1]), batch)))\n",
    "    if hasattr(batch[0][0], \"x_tensor\"):\n",
    "        return torch.stack(list(map(lambda x: x[0].x_tensor, batch))), torch.stack(list(map(getSegmentationMask, batch))).long()\n",
    "    else:\n",
    "        return torch.stack(list(map(lambda x: x[0].px, batch))), torch.stack(list(map(lambda x: x[1].px, batch))).long()\n",
    "\n",
    "def getSegmentationMask(dan):\n",
    "    y, x = dan[0].y_tensor, dan[0].x_tensor\n",
    "    res = ((y[0] == x[0]).int() + (y[1] == x[1]).int() + (x[2] == y[2]).int()) != 3\n",
    "    res = res.unsqueeze(0)\n",
    "    return res    \n",
    "    \n",
    "def folder(p):\n",
    "    folder = (\"0000\" + p[-7:-4])[-4:]\n",
    "    return '/' + folder + \"/\" + p \n",
    "\n",
    "\n",
    "class CustomItem(ItemBase):\n",
    "    def __init__(self, image):\n",
    "        self.image = image\n",
    "        self.data = 0\n",
    "    \n",
    "    def __str__(self): return str(self.image)\n",
    "        \n",
    "    def apply_tfms(self, tfms, **kwargs):\n",
    "        for tfm in tfms:\n",
    "            tfm(self, **kwargs)\n",
    "        return self  \n",
    "\n",
    "class CustomLabel(SegmentationLabelList):\n",
    "    def open(self, fn):\n",
    "        return ImageSegment(torch.zeros(1, 64, 64))    \n",
    "    \n",
    "class CustomItemList(SegmentationItemList):  \n",
    "    _label_cls = CustomLabel\n",
    "    def get(self, i):\n",
    "        return self.reconstruct(pilImage.open(self.items[i]).convert('RGB'))\n",
    "    \n",
    "    def reconstruct(self, t):\n",
    "        return CustomItem(t)\n",
    "\n",
    "\n",
    "fonts = Fonts(Fonts.load(Path('../fonts')))\n",
    "with open(EXPERIMENT_PATH / 'text_info.json', 'r') as f:\n",
    "    info = json.load(f)\n",
    "\n",
    "random_seed(42)\n",
    "allData = getData()   \n",
    "    \n",
    "items = list(map(lambda p: DANBOORU_PATH + folder(p), filter(lambda k: info[k] == 0, info.keys())))\n",
    "\n",
    "data = CustomItemList(items[0:10]).split_none().label_const('a', classes=['text'])\n",
    "\n",
    "data.valid = getDatasets(allData)[0].valid\n",
    "\n",
    "data.train.transform([partial(textify, fonts=fonts), tensorize])\n",
    "\n",
    "data = data.databunch(bs=8, val_bs = 2, collate_fn = custom_collate).normalize(imagenet_stats)\n",
    "\n",
    "learn = unet_learner(data, models.resnet18, metrics=[accuracy_thresh, partial(accuracy_thresh, thresh=0.95, sigmoid=False)], loss_func=custom_loss, y_range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cntIndex = 0\n",
    "if cv2.__version__.startswith(\"3\"):\n",
    "    cntIndex = 1\n",
    "\n",
    "def expand(mask, img):\n",
    "    mask = mask.astype('uint8')\n",
    "    gray = cv2.cvtColor(img.data.mul(255).permute(1,2,0).numpy().astype('uint8'),cv2.COLOR_RGB2GRAY)\n",
    "    thresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,15,30)\n",
    "    cnts = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[cntIndex]\n",
    "    im3 = np.zeros(thresh.shape, np.uint8)\n",
    "\n",
    "    for c in cnts:\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        thresh = cv2.adaptiveThreshold(gray[y:y+h, x:x+w],255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,15,30)\n",
    "        ret, markers = cv2.connectedComponents(cv2.bitwise_not(thresh), connectivity=8)\n",
    "        if ret < 10:\n",
    "            for label in range(1,ret):\n",
    "                m = markers == label\n",
    "                if m.sum() > 3:\n",
    "                    if (m & mask[y:y+h, x:x+w] > 0).sum() > m.sum() * 0.1:\n",
    "                        im3[y:y+h, x:x+w][m] = 255\n",
    "    \n",
    "    return im3\n",
    "def removeNoise(mask):\n",
    "    cnts = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[cntIndex]\n",
    "    goods = [cv2.contourArea(c) >= 50 for c in cnts]\n",
    "    rects = [cv2.boundingRect(c) for c in cnts]\n",
    "    circles = [cv2.minEnclosingCircle(c) for c in cnts]\n",
    "    banned = [False] * len(cnts)\n",
    "        \n",
    "    m = cv2.dilate(mask,(5, 5),iterations = 7)\n",
    "    cc = cv2.findContours(m, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)[cntIndex] \n",
    "    rr = [cv2.boundingRect(c) for c in cc]\n",
    "\n",
    "    for c, good, idx, rect in zip(cnts, goods, range(0, len(cnts)), rects):\n",
    "        x,y,w,h = rect\n",
    "        \n",
    "        if max(w,h) / min(w,h) > 5:\n",
    "            goods[idx] = False\n",
    "            if max(w,h) / min(w,h) > 8:\n",
    "                banned[idx] = True\n",
    "                continue\n",
    "        \n",
    "        for r2, c2 in zip(rr, cc):\n",
    "            x2, y2, w2, h2 = r2\n",
    "            if cv2.contourArea(c2) >= 50 and x >= x2 and x + w <= x2 + w2 and y >= y2 and y + h <= y2 + h2 and (mask[y2:y2+h2, x2:x2+w2] > 0).sum() > len(c2) * 0.5:\n",
    "                goods[idx] = True    \n",
    "\n",
    "    \n",
    "    changed = True\n",
    "    while changed:\n",
    "        changed = False\n",
    "        for c, good, idx, rect in zip(cnts, goods, range(0, len(cnts)), rects):\n",
    "            if banned[idx]:\n",
    "                continue\n",
    "                \n",
    "            x,y,w,h = rect\n",
    "            x, y = x + w / 2, y + h / 2 \n",
    "            if not good:\n",
    "                for a in range(max(idx - 50, 0), len(cnts)):\n",
    "                    if a != idx and goods[a]:\n",
    "                        x2, y2, w2, h2 = rects[a]\n",
    "                        x2, y2, = x2 + w2 / 2, y2 + h2 / 2 \n",
    "                        \n",
    "                        if abs(y2 - y) > 100 + h:\n",
    "                            break\n",
    "                        \n",
    "                        if abs (cv2.contourArea(cnts[idx]) - circles[idx][1]**2) > 20 and abs(y2 - y) < (h + h2) / 2 + 20 and abs(x2 - x) < (w + w2) / 2 + 20:\n",
    "                            good = goods[idx] = True\n",
    "                            changed = True\n",
    "                            break\n",
    "\n",
    " \n",
    "\n",
    "    for c, good, idx, rect in zip(cnts, goods, range(0, len(cnts)), rects):                        \n",
    "        if not good:\n",
    "            cv2.drawContours(mask, [c], 0, (0, 0, 0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(EXPERIMENT_PATH / 'models' / 'v1_2');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (EXPERIMENT_PATH / 'v1_2 predictions.csv').exists() or True:\n",
    "    for index, dataset in enumerate(getDatasets(allData, crop=False, cutInHalf = False)):\n",
    "        random_seed(42)\n",
    "        m = MetricsCallback(None)\n",
    "        m.on_train_begin()\n",
    "        for idx in range(len(dataset.valid.x.items)):\n",
    "            x = dataset.valid.x.get(idx, False)\n",
    "            y = learn.predict(x)[2] > 0.95\n",
    "            y = y.permute(1,2,0).numpy() * 255\n",
    "            y = expand(y[:,:,0], x)\n",
    "            removeNoise(y)\n",
    "            y = tensor(y).unsqueeze(0).div_(255).bool()\n",
    "            m.on_batch_end(False, y, dataset.valid.y.get(idx, False).px)\n",
    "        m.calculateMetrics() \n",
    "        m.save(EXPERIMENT_PATH / 'v1_2 predictions.csv', index > 0)            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
