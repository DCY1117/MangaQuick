{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from fastai.vision import unet_learner, imagenet_stats, torch, Path, os, load_learner, models, ItemBase, SegmentationLabelList, SegmentationItemList, partial, ImageSegment\n",
    "from experiments import getDatasets, getData, random_seed\n",
    "from losses import MixedLoss\n",
    "from metrics import MetricsCallback, getDatasetMetrics\n",
    "from fastai.callbacks import CSVLogger, SaveModelCallback\n",
    "from config import *\n",
    "import glob\n",
    "from TextGenerator import Fonts\n",
    "from transforms import textify, tensorize\n",
    "from PIL import Image as pilImage\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_PATH = Path(EXPERIMENTS_PATH) / 'synthetic'\n",
    "MODELS_PATH = EXPERIMENT_PATH / \"models\"\n",
    "os.makedirs(MODELS_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = load_learner(Path(EXPERIMENTS_PATH) / 'model/resnet34/0', 'final refined model 2.pkl')\n",
    "\n",
    "if (EXPERIMENT_PATH / 'text_info.json').exists():\n",
    "    with open(EXPERIMENT_PATH / 'text_info.json', 'r') as f:\n",
    "        info = json.load(f)\n",
    "else:\n",
    "    info = dict()\n",
    "\n",
    "for file in glob.glob(DANBOORU_PATH + '/**/*.jpg', recursive=True):\n",
    "    file = Path(file)\n",
    "    if file.name not in info:\n",
    "        pred = learn.predict(open_image(file))[2]\n",
    "        pred = torch.sigmoid(pred) > 0.5\n",
    "        info[file.name] = (pred == 1).sum().item()\n",
    "        with open(EXPERIMENT_PATH / 'text_info.json', 'w') as f:\n",
    "            json.dump(info, f)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData = getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    if hasattr(batch[0][0], \"x_tensor\"):\n",
    "        return torch.stack(list(map(lambda x: x[0].x_tensor, batch))), torch.stack(list(map(getSegmentationMask, batch))).long()\n",
    "    else:\n",
    "        return torch.stack(list(map(lambda x: x[0].px, batch))), torch.stack(list(map(lambda x: x[1].px, batch))).long()\n",
    "\n",
    "def getSegmentationMask(dan):\n",
    "    return ((dan[0].x_tensor - dan[0].y_tensor).abs().sum(axis=0) > 0.1).unsqueeze(0)\n",
    "    \n",
    "def folder(p):\n",
    "    folder = (\"0000\" + p[-7:-4])[-4:]\n",
    "    return '/' + folder + \"/\" + p \n",
    "\n",
    "\n",
    "class CustomItem(ItemBase):\n",
    "    def __init__(self, image):\n",
    "        self.image = image\n",
    "        self.data = 0\n",
    "    \n",
    "    def __str__(self): return str(self.image)\n",
    "        \n",
    "    def apply_tfms(self, tfms, **kwargs):\n",
    "        for tfm in tfms:\n",
    "            tfm(self, **kwargs)\n",
    "        return self  \n",
    "\n",
    "class CustomLabel(SegmentationLabelList):\n",
    "    def open(self, fn):\n",
    "        return ImageSegment(torch.zeros(1, 64, 64))    \n",
    "    \n",
    "class CustomItemList(SegmentationItemList):  \n",
    "    _label_cls = CustomLabel\n",
    "    def get(self, i):\n",
    "        return self.reconstruct(pilImage.open(self.items[i]).convert('RGB'))\n",
    "    \n",
    "    def reconstruct(self, t):\n",
    "        return CustomItem(t)\n",
    "\n",
    "    \n",
    "fonts = Fonts(Fonts.load(Path('../fonts')))\n",
    "\n",
    "items = list(map(lambda p: DANBOORU_PATH + folder(p), filter(lambda k: info[k] == 0, info.keys())))\n",
    "\n",
    "data = CustomItemList(items).split_none().label_const('a', classes=['text'])\n",
    "data.valid = getDatasets(allData)[0].valid\n",
    "\n",
    "data.train.transform([partial(textify, fonts=fonts), tensorize])\n",
    "\n",
    "data = data.databunch(bs=8, val_bs = 2, collate_fn = custom_collate).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = unet_learner(data, models.resnet34, callback_fns=[MetricsCallback, CSVLogger, partial(SaveModelCallback, monitor = 'ignore global f1 score %')], model_dir='models', loss_func=MixedLoss(0, 1), path=EXPERIMENT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (EXPERIMENT_PATH / 'final model.pkl').exists():\n",
    "    random_seed(42)\n",
    "    learn.fit_one_cycle(5, 1e-4)\n",
    "    learn.save('model')\n",
    "    learn.export('final model.pkl')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (EXPERIMENT_PATH / 'final predictions.csv').exists():\n",
    "    learn = load_learner(EXPERIMENT_PATH, 'final model.pkl')\n",
    "    for index, dataset in enumerate(getDatasets(allData, crop=False, cutInHalf = False)):\n",
    "        random_seed(42)\n",
    "        m = getDatasetMetrics(dataset, learn)\n",
    "        m.save(EXPERIMENT_PATH / 'final predictions.csv', index > 0)            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
